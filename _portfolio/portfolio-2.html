---
title: "Video Future Frames Generation using deep Encoder-decoder based Hierarchical Network<br>
        <small>[<a href='https://github.com/Dhagash4/video-prediction'>code</a>]</small>
        <small>[<a href='https://github.com/Dhagash4/video-prediction'>pdf</a>]</small>"
excerpt: "<p> <img  style='float: left;' width='200' height='200' margin= 'auto' src='/images/extended_model.jpg'>
    Video frames generation is a challenging task due to the wide uncertainty in the nature of the problem. 
    In this lab project, we approach the task of the video prediction using the model discussed in the lab, based on the Video Ladder Network.
    In our work, the moving Moving MNIST (MMNIST) and the KTH Action dataset are being used to perform the experiments. 
    We present the effects of various design choices in the model architectures and the training settings. 
    The final results achieved on both datasets are realistic and coherent with the given context frames, indicating the strong learning capability of the network.</p>"
---

<h1>
Video Future Frames Generation using deep Encoder-decoder based Hierarchical Network<br>
<small>[<a href='https://github.com/Dhagash4/video-prediction'>code</a>]</small>
<small>[<a href='https://github.com/Dhagash4/video-prediction'>pdf</a>]</small>
</h1>

Video frames generation is a challenging task due to the wide uncertainty in the nature of the problem. 
In this lab project, we approach the task of the video prediction using the model discussed in the lab, based on the Video Ladder Network.
In this work, the moving Moving MNIST (MMNIST) and the KTH Action dataset are being used to perform the experiments. 
We present the effects of various design choices in the model architectures and the training settings. 
The final results achieved on both datasets are realistic and coherent with the given context frames, indicating the strong learning capability of the network.
<style>
    img {
      max-width: 100%;
    }
</style>

<img src='/images/extended_model.jpg'>
<div class="caption">Netwrok architecture: Extension to baseline model with the addition of skip
    connections, encoder-decoder blocks are residual blocks.</div>

<h2>Results on MMNIST</h2>

<p>
<img src="/images/all_frames1_random_batch_mmnist.gif">
<img src="/images/all_frames2_random_batch_mmnist.gif">
<img src="/images/all_frames3_random_batch_mmnist.gif">
<img src="/images/all_frames4_random_batch_mmnist.gif">
<img src="/images/all_frames5_random_batch_mmnist.gif">
<img src="/images/all_frames6_random_batch_mmnist.gif">
<img src="/images/all_frames7_random_batch_mmnist.gif">
<img src="/images/all_frames8_random_batch_mmnist.gif">
<img src="/images/all_frames9_random_batch_mmnist.gif">
<img src="/images/all_frames10_random_batch_mmnist.gif">
</p>

<h2>Results on KTH Action</h2>
<p>
<img src = "/images/all_frames1_random_batch_kth.gif">
<img src = "/images/all_frames2_random_batch_kth.gif">
<img src = "/images/all_frames3_random_batch_kth.gif">
<img src = "/images/all_frames4_random_batch_kth.gif">
<img src = "/images/all_frames5_random_batch_kth.gif">
<img src = "/images/all_frames6_random_batch_kth.gif">
<img src = "/images/all_frames7_random_batch_kth.gif">
<img src = "/images/all_frames8_random_batch_kth.gif">
<img src = "/images/all_frames9_random_batch_kth.gif">
<img src = "/images/all_frames10_random_batch_kth.gif">
</p>


