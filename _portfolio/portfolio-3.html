---
title: "Effect of Biased Training Data on Loss Landscape of Deep Neural Newworks<br>
        <small>[<a href='https://github.com/ali-mohammadi-scrc/ML_Lab'>code</a>]</small>
        <small>[<a href='http://amitrana001.github.io/files/loss-landscape-generalization.pdf'>pdf</a>]</small>"
excerpt: " <p> <img  style='float: left;' width='200' height='200' margin= 'auto' src='/images/2Dvisual.png'> 
            Many studies show a positive correlation between the generalization ability of a
            deep neural network and the flatness of the minima in its loss landscape. Inspired
            by this statement, many studies investigate the effect of using different training pa-
            rameters and network architecture on the loss landscape of the neural network. This
            study investigates the effect of training a deep neural network on a biased dataset on
            its loss landscape by visualizing the loss landscape of the trained model. We found
            that different types of biases in the training dataset can affect the geometry of the loss
            landscape around the minima.</p>
---

<style>
    img {
      max-width: 100%;
    }
</style>

<img src='/images/2Dvisual.png'>
<div class="caption">Netwrok architecture: Extension to baseline model with the addition of skip
    connections, encoder-decoder blocks are residual blocks.</div>

<h2>Abstract</h2>
Many studies show a positive correlation between the generalization ability of a
deep neural network and the flatness of the minima in its loss landscape. Inspired
by this statement, many studies investigate the effect of using different training pa-
rameters and network architecture on the loss landscape of the neural network. This
study investigates the effect of training a deep neural network on a biased dataset on
its loss landscape by visualizing the loss landscape of the trained model. We found
that different types of biases in the training dataset can affect the geometry of the loss
landscape around the minima.